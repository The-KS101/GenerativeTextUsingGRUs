{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Shakespeare GRU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP/0oMM6g9sF22TkkPdw3lY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/The-KS101/GenerativeTextUsingGRUs/blob/master/StateOfUnion_GRU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6sRxu3H4gI3",
        "colab_type": "text"
      },
      "source": [
        "###Using time series Deep Learning tools to build a character Level Language Model\n",
        "####Creating an RNN model to derive a language model \n",
        "#####Import the necessary libraries\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hA-6AFP3qmG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "624d2396-4044-4505-9122-c733ba7e2bee"
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import pickle\n",
        "import random\n",
        "import re\n",
        "import os\n",
        "from nltk.corpus import gutenberg\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Bidirectional, Dropout\n",
        "from keras.layers import BatchNormalization, SimpleRNN, GRU\n",
        "from keras.callbacks import LambdaCallback, ModelCheckpoint\n",
        "from keras.utils.data_utils import get_file\n",
        "from __future__ import print_function"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlgkmYsb8vUh",
        "colab_type": "text"
      },
      "source": [
        "Firstly we download the state union pack from nltk corpus which contains various text corpus of state union documents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SuMF49L7rIY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "1bad5b09-8997-41e4-e653-245f36d40e02"
      },
      "source": [
        "import nltk\n",
        "nltk.download('state_union')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/state_union.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VPxFIE49Rk7",
        "colab_type": "text"
      },
      "source": [
        "Here we import all the documents in the state union folder and get all the words into a text variable which we will process for our train and test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gisRXPP24e2B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cf041888-5e56-431b-82f6-848743b37f40"
      },
      "source": [
        "corpora_dir = '/root/nltk_data/corpora/state_union'\n",
        "file_list = []\n",
        "docs = []\n",
        "\n",
        "for root, _, files in os.walk(corpora_dir):\n",
        "  for filename in files:\n",
        "    file_list.append(os.path.join(corpora_dir, filename))\n",
        "\n",
        "print('Read {} files'.format(len(file_list)))\n",
        "for files in file_list:\n",
        "  with open(files, 'r') as fin:\n",
        "    try:\n",
        "      str_fin = fin.read().lower().replace('\\n', '')\n",
        "      docs.append(str_fin)\n",
        "    except UnicodeDecodeError:\n",
        "      pass\n",
        "\n",
        "text = ' '.join(docs)\n",
        "print('Corpus Length is ' + str(len(text)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Read 66 files\n",
            "Corpus Length is 1915949\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLkRyMKT-c4M",
        "colab_type": "text"
      },
      "source": [
        "Now we map our letters to numbers which, as we know, is what our computer program runs through. To do this we will create 2 dictionaries mapping each letter to a number and each number to a letter for ease."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1lw1GA3-vjK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "37261869-c22b-48c1-9632-eeffbb0d164b"
      },
      "source": [
        "characters = sorted(list(set(text)))\n",
        "print('Total Characters: ', len(characters))\n",
        "charIndices = dict((l, i) for i, l in enumerate(characters))\n",
        "indicesChar = dict((i, l) for i, l in enumerate(characters))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  57\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWDisLaG_voe",
        "colab_type": "text"
      },
      "source": [
        "Now we break up te text into smaller splits which we will feed our neural network. This splits will contain 40 input characters and 1 output character per sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcmrG9VFAFD2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_seq = []\n",
        "output_char = []\n",
        "seq_length, stride = 40, 3\n",
        "for i in range(0, len(text)-seq_length, stride):\n",
        "  training_seq.append(text[i : i +seq_length])\n",
        "  output_char.append(text[i + seq_length])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIg9GawzB0xM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "e3c284c9-229b-4004-8ebf-d7954d62e969"
      },
      "source": [
        "print('Number of training rows: ', len(training_seq))\n",
        "print('First Sequence: ', training_seq[0])\n",
        "print('Next char: ', output_char[0])\n",
        "print('Second Sequence: ', training_seq[1])\n",
        "print('Next char: ', output_char[1])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training rows:  638637\n",
            "First Sequence:  president bill clinton's address before \n",
            "Next char:  a\n",
            "Second Sequence:  sident bill clinton's address before a j\n",
            "Next char:  o\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1oCsvuPEL3C",
        "colab_type": "text"
      },
      "source": [
        "Now we vectorize our input texts and one hot encode each variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzZw206JELGj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "ea32e96f-b09b-4078-9a05-cc0115952ed3"
      },
      "source": [
        "x = np.zeros((len(training_seq), seq_length, len(characters)), dtype=np.bool)\n",
        "y = np.zeros((len(training_seq), len(characters)), dtype=np.bool)\n",
        "for i, sequence in enumerate(training_seq):\n",
        "  for j, char in enumerate(sequence):\n",
        "    x[i, j, charIndices[char]] = 1\n",
        "  y[i, charIndices[output_char[i]]] = 1\n",
        "print('Data Vectorization Completed.')\n",
        "print('Feature Vector Space: ', x.shape)\n",
        "print('Label vector space: ', y.shape)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Vectorization Completed.\n",
            "Feature Vector Space:  (638637, 40, 57)\n",
            "Label vector space:  (638637, 57)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90aYjkxYu2Us",
        "colab_type": "text"
      },
      "source": [
        "We now creat a function that uses threshold sampling to redistribute the softmax prediction probabilitites of our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrqRWiSJvOIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(softmax_predictions, sample_threshold=0.1):\n",
        "  softmax_preds = np.asarray(softmax_predictions).astype('float64')\n",
        "  log_preds = np.log(softmax_preds)/sample_threshold\n",
        "  exp_preds = np.exp(log_preds)\n",
        "  norm_preds = exp_preds/np.sum(exp_preds)\n",
        "  prob = np.random.multinomial(1, norm_preds, 1)\n",
        "  return np.argmax(prob)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ndgq0-xW0xvu",
        "colab_type": "text"
      },
      "source": [
        "Now we build our neural network, we will create multiple neural networks to test their performance in generating texts with respect to Hamlet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4EY6z2X0w8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#First we create a callback function\n",
        "def on_epoch_end(epoch, _):\n",
        "  global model, model_name\n",
        "  print()\n",
        "  print('----- Generating text after Epoch: {}'.format(epoch))\n",
        "  start_index = random.randint(0, len(text) - seq_length - 1)\n",
        "  end_index = start_index + seq_length\n",
        "  sampThresh = [0.2, 0.5, 1.0, 1.2]\n",
        "  for thresh in sampThresh:\n",
        "    print('----Sampling Threshold : ', thresh)\n",
        "    generated = ''\n",
        "    sentence = text[start_index:end_index]\n",
        "    generated += sentence\n",
        "    print('Input sequence to generate from \"{}\" '.format(sentence))\n",
        "    sys.stdout.write(generated)\n",
        "    for i in range(400):\n",
        "      x_pred = np.zeros((1, seq_length, len(characters)))\n",
        "      for n, char in enumerate(sentence):\n",
        "        x_pred[0, n, charIndices[char]] = 1\n",
        "      preds = model.predict(x_pred, verbose=0)[0]\n",
        "      next_index = sample(preds, thresh)\n",
        "      next_char = indicesChar[next_index]\n",
        "      generated += next_char\n",
        "      sentence = sentence[1:] + next_char\n",
        "      sys.stdout.write(next_char)\n",
        "      sys.stdout.flush()\n",
        "    print()\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKqU9tAgvAQT",
        "colab_type": "text"
      },
      "source": [
        "Now we create a helper function to train, sample and save a list of RNN models.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByJgT-xZvM5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_models(lists, epochs=10):\n",
        "  global model, model_name\n",
        "\n",
        "  for net in lists:\n",
        "    print('Initiating Compilation...')\n",
        "    model = net()\n",
        "    model_name = re.split(' ', str(net))[1]\n",
        "    fp = '/content/sample_data/{}.h5'.format(model_name)\n",
        "    checkpoint = ModelCheckpoint(fp, monitor='loss',\n",
        "                                 verbose=0, save_best_only=True, mode='min')\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "    print('Compiled: ', str(model_name))\n",
        "    network = model.fit(x, y, batch_size=128,\n",
        "                        epochs=epochs, callbacks=[print_callback, checkpoint])\n",
        "    model.summary()\n",
        "    with open('/content/sample_data/{}hist.pkl'.format(model_name)\n",
        "              , 'wb') as file_pi:\n",
        "      pickle.dump(model.history, file_pi)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWzVc3W2yyDe",
        "colab_type": "text"
      },
      "source": [
        "Now we create multiple RNNs and GRUs to test the output of various neural networks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4TCHgmOy5Ey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Simple RNN Stacked Model\n",
        "def SimpleRNN_stacked_model():\n",
        "  model=Sequential()\n",
        "  model.add(SimpleRNN(128, input_shape=(seq_length, len(characters)),\n",
        "                      return_sequences=True))\n",
        "  model.add(SimpleRNN(128))\n",
        "  model.add(Dense(len(characters), activation='softmax'))\n",
        "  return model\n",
        "\n",
        "#GRU model\n",
        "def GRU_stacked_model():\n",
        "  model = Sequential()\n",
        "  model.add(GRU(128, input_shape=(seq_length, len(characters)),\n",
        "                return_sequences=True))\n",
        "  model.add(GRU(128))\n",
        "  model.add(Dense(len(characters), activation='softmax'))\n",
        "  return model\n",
        "\n",
        "#Bidirectional GRU\n",
        "def Bi_directional_GRU():\n",
        "  model = Sequential()\n",
        "  model.add(Bidirectional(GRU(128, input_shape=(seq_length, len(characters)),\n",
        "                              return_sequences=True)))\n",
        "  model.add(Bidirectional(GRU(128)))\n",
        "  model.add(Dense(len(characters), activation='softmax'))\n",
        "  return model\n",
        "\n",
        "#Larger GRU\n",
        "def larger_GRU():\n",
        "  model = Sequential()\n",
        "  model.add(GRU( 128, input_shape=(seq_length, len(characters)),\n",
        "                return_sequences=True, dropout=0.2,  recurrent_dropout=0.2))\n",
        "  model.add(GRU(128, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
        "  model.add(GRU(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dense(len(characters), activation='softmax'))\n",
        "  return model"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IV5lpbvA4_kw",
        "colab_type": "text"
      },
      "source": [
        "We now pass all the created models to a list to be passed to the test_models function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fdESce15G4J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "de95a8cc-c47a-469c-d6c0-a3f42f351028"
      },
      "source": [
        "print(seq_length)\n",
        "all_models = [GRU_stacked_model,\n",
        "              SimpleRNN_stacked_model,\n",
        "              Bi_directional_GRU,\n",
        "              larger_GRU]\n",
        "test_models(all_models, epochs=1)            "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40\n",
            "Initiating Compilation...\n",
            "Compiled:  GRU_stacked_model\n",
            "Epoch 1/1\n",
            "638637/638637 [==============================] - 1644s 3ms/step - loss: 1.8122\n",
            "\n",
            "----- Generating text after Epoch: 0\n",
            "----Sampling Threshold :  0.2\n",
            "Input sequence to generate from \"s.tonight i propose a 21st century crime\" \n",
            "s.tonight i propose a 21st century crime the must continue that we must be a states the program that we have the programs of the program to all the program that we have the program to continue the united to all the program that we have the fare the states and the programs which the america the american make the world and the america the program to all state the many of the program the make the programs who have a states will be a state \n",
            "----Sampling Threshold :  0.5\n",
            "Input sequence to generate from \"s.tonight i propose a 21st century crime\" \n",
            "s.tonight i propose a 21st century crime to vites than more energy of the bolds of the america for a many in program than a commistive program we must a state the real states for the united that when the propest to growth them we have revelop, still resorve of the states will not remore of the programs make their every have stately and the know are nation in we must make have president endight of those will pal will be the dollars will \n",
            "----Sampling Threshold :  1.0\n",
            "Input sequence to generate from \"s.tonight i propose a 21st century crime\" \n",
            "s.tonight i propose a 21st century crime with it in these abread. they we which a mainfile. we is eriegh, these congrous by preseft ark nation statured. this not of eleme killed, it'se that was the payking and levely having spilitading state will include as ecoromy that makeres this fairh. we have our payter.  ) their takn stake ot rmunibility, contibur, econemy to likst will resoge.where say 19jobly for a in teach, because have caured \n",
            "----Sampling Threshold :  1.2\n",
            "Input sequence to generate from \"s.tonight i propose a 21st century crime\" \n",
            "s.tonight i propose a 21st century crime hame this governe:wich ;ur palian. amerima.  nate-said, notheds artatulity prograsss, we are nefict, wanking turnch, poon for them.0reafue whick to kerign pooply rog that home as, they mult. where will regrest askated all price protima scome this. 10 19've, creative warks's seach hove must in that cliinatia roupigated the fies of ple shalth pinsive a war, and coupaifities, and spagedquit. that la\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_1 (GRU)                  (None, 40, 128)           71424     \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (None, 128)               98688     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 57)                7353      \n",
            "=================================================================\n",
            "Total params: 177,465\n",
            "Trainable params: 177,465\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Initiating Compilation...\n",
            "Compiled:  SimpleRNN_stacked_model\n",
            "Epoch 1/1\n",
            "638637/638637 [==============================] - 357s 558us/step - loss: 1.9124\n",
            "\n",
            "----- Generating text after Epoch: 0\n",
            "----Sampling Threshold :  0.2\n",
            "Input sequence to generate from \" arise across the atlantic a trading par\" \n",
            " arise across the atlantic a trading part and the save and a can strong on the world to which and we must and we must and the world and we have to a community and the security and the and we have and the and the first to a can strong we see sarked and strengther the american and responsibility and a comminition the sare the program and in the serve to and the program and we have and to the adering to and the security and the american se\n",
            "----Sampling Threshold :  0.5\n",
            "Input sequence to generate from \" arise across the atlantic a trading par\" \n",
            " arise across the atlantic a trading part at have and wirlance to restial people with the recond. and we will all conthing and the grom. the need, be a to are to the fear and be all a can and end world be bet on the and should and has the lown the program best on that recomenting american we must american we have and the and the we sal the recommended by will to the sation of in the peace and on me the american propose a can the far ach\n",
            "----Sampling Threshold :  1.0\n",
            "Input sequence to generate from \" arise across the atlantic a trading par\" \n",
            " arise across the atlantic a trading part tonybew whole on that thew. i and ynarancence of resourcenn. we kaft and firmbausking to ally heong engage, their lawar, in betond this geendong privisen, we agen cropres., we fad we hooderre's fraciting alared plowed thant saind inventmes gremem fin dasions astleis.we cigas an and recosporita, and am-wely atame for miving and edpicatnmy lisrobe enoud this can resosires weorly, to cancern spand \n",
            "----Sampling Threshold :  1.2\n",
            "Input sequence to generate from \" arise across the atlantic a trading par\" \n",
            " arise across the atlantic a trading parcen yeop on the aret.for our must in it grom,- all stirling and groadg, all.in abthing and hadon meched a betinosis.it wto's  batton, oner and acligis, knovilation and ont, beegit-censatarity.in one recreal sament. canding: on semuld be ongose rass. yound undort responserce.the self poselve. we'ragenimatingnamy mower torregtpone, that ecfion---arthin gogot. this world, otssinven rasking pate the f\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_1 (SimpleRNN)     (None, 40, 128)           23808     \n",
            "_________________________________________________________________\n",
            "simple_rnn_2 (SimpleRNN)     (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 57)                7353      \n",
            "=================================================================\n",
            "Total params: 64,057\n",
            "Trainable params: 64,057\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Initiating Compilation...\n",
            "Compiled:  Bi_directional_GRU\n",
            "Epoch 1/1\n",
            "480768/638637 [=====================>........] - ETA: 14:53 - loss: 1.8341"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}